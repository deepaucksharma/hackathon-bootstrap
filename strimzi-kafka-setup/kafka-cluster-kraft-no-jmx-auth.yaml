apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: dual-role
  namespace: strimzi-kafka
  labels:
    strimzi.io/cluster: production-kafka
spec:
  replicas: 3
  roles:
    - controller
    - broker
  storage:
    type: jbod
    volumes:
      - id: 0
        type: persistent-claim
        size: 100Gi
        kraftMetadata: shared
        deleteClaim: false
  resources:
    requests:
      memory: 2Gi
      cpu: "1000m"
    limits:
      memory: 4Gi
      cpu: "2000m"
  jvmOptions:
    -Xms: 1536m
    -Xmx: 1536m
    gcLoggingEnabled: true
    # Add JMX system properties to disable authentication
    javaSystemProperties:
      - name: com.sun.management.jmxremote.authenticate
        value: "false"
      - name: com.sun.management.jmxremote.ssl
        value: "false"
---
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: production-kafka
  namespace: strimzi-kafka
  annotations:
    strimzi.io/node-pools: enabled
    strimzi.io/kraft: enabled
spec:
  kafka:
    version: 3.9.0
    metadataVersion: 3.9-IV0
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
    config:
      # Kafka broker configuration
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      # Performance tuning
      num.network.threads: 8
      num.io.threads: 8
      socket.send.buffer.bytes: 102400
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
      # Log configuration
      log.retention.hours: 168
      log.segment.bytes: 1073741824
      log.retention.check.interval.ms: 300000
      # Enable auto topic creation
      auto.create.topics.enable: true
      delete.topic.enable: true
    authorization:
      type: simple
      superUsers:
        - cluster-operator
    # JMX Configuration - disable authentication for monitoring
    jmxOptions: {}
    metricsConfig:
      type: jmxPrometheusExporter
      valueFrom:
        configMapKeyRef:
          name: kafka-metrics
          key: kafka-metrics-config.yml
    # Add template to configure JMX without authentication
    template:
      pod:
        metadata:
          annotations:
            jmx.disable.authentication: "true"
        affinity:
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchLabels:
                    strimzi.io/cluster: production-kafka
                    strimzi.io/kind: Kafka
                    strimzi.io/name: production-kafka-kafka
                topologyKey: kubernetes.io/hostname
  entityOperator:
    topicOperator:
      resources:
        requests:
          memory: 512Mi
          cpu: "200m"
        limits:
          memory: 1Gi
          cpu: "500m"
    userOperator:
      resources:
        requests:
          memory: 512Mi
          cpu: "200m"
        limits:
          memory: 1Gi
          cpu: "500m"
  kafkaExporter:
    topicRegex: ".*"
    groupRegex: ".*"
    resources:
      requests:
        memory: 128Mi
        cpu: "100m"
      limits:
        memory: 256Mi
        cpu: "500m"
---
# Metrics ConfigMap remains the same
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-metrics
  namespace: strimzi-kafka
data:
  kafka-metrics-config.yml: |
    # Kafka metrics configuration for Prometheus JMX exporter
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
    # Special cases and very specific rules
    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
       clientId: "$3"
       topic: "$4"
       partition: "$5"
    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
       clientId: "$3"
       broker: "$4:$5"
    - pattern: kafka.server<type=(.+), cipher=(.+), protocol=(.+), listener=(.+), networkProcessor=(.+)><>connections
      name: kafka_server_$1_connections_tls_info
      type: GAUGE
      labels:
        cipher: "$2"
        protocol: "$3"
        listener: "$4"
        networkProcessor: "$5"
    - pattern: kafka.server<type=(.+), clientSoftwareName=(.+), clientSoftwareVersion=(.+), listener=(.+), networkProcessor=(.+)><>connections
      name: kafka_server_$1_connections_software
      type: GAUGE
      labels:
        clientSoftwareName: "$2"
        clientSoftwareVersion: "$3"
        listener: "$4"
        networkProcessor: "$5"
    - pattern: "kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+):"
      name: kafka_server_$1_$4
      type: GAUGE
      labels:
       listener: "$2"
       networkProcessor: "$3"
    - pattern: kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+)
      name: kafka_server_$1_$4
      type: GAUGE
      labels:
       listener: "$2"
       networkProcessor: "$3"
    # Common rules
    - pattern: kafka.server<type=(.+), name=(.+), topic=(.+), partition=(.*)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
       topic: "$3"
       partition: "$4"
    - pattern: kafka.server<type=(.+), name=(.+), topic=(.+)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
       topic: "$3"
    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
       clientId: "$3"
    - pattern: kafka.server<type=(.+), name=(.+)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
    - pattern: "kafka.server<type=(.+), name=(.+)><>(.+):"
      name: kafka_server_$1_$2
      type: GAUGE
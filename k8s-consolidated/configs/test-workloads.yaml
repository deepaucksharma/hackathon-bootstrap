# Test workloads for generating Kafka traffic
# Ensures metrics are populated for verification

---
# Test Topics
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: test-topic
  namespace: strimzi-kafka
  labels:
    strimzi.io/cluster: production-kafka
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 7200000
    segment.bytes: 1073741824
    min.insync.replicas: 2

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: metrics-topic
  namespace: strimzi-kafka
  labels:
    strimzi.io/cluster: production-kafka
spec:
  partitions: 6
  replicas: 3
  config:
    retention.ms: 3600000
    compression.type: snappy
    min.insync.replicas: 2

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: events-topic
  namespace: strimzi-kafka
  labels:
    strimzi.io/cluster: production-kafka
spec:
  partitions: 12
  replicas: 3
  config:
    retention.ms: 86400000
    compression.type: lz4
    segment.bytes: 536870912

---
# High-throughput test producer
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-producer-high-throughput
  namespace: strimzi-kafka
spec:
  replicas: 2
  selector:
    matchLabels:
      app: kafka-producer-high-throughput
  template:
    metadata:
      labels:
        app: kafka-producer-high-throughput
    spec:
      containers:
      - name: producer
        image: strimzi/kafka:latest-kafka-3.3.1
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "500m"
        command:
        - /bin/bash
        - -c
        - |
          # Generate high-throughput traffic
          while true; do
            # Produce to multiple topics
            for topic in test-topic metrics-topic events-topic; do
              for i in {1..100}; do
                echo "{\"timestamp\":$(date +%s),\"value\":$RANDOM,\"host\":\"$HOSTNAME\",\"topic\":\"$topic\"}" | \
                  /opt/kafka/bin/kafka-console-producer.sh \
                  --bootstrap-server production-kafka-kafka-bootstrap:9092 \
                  --topic $topic &
              done
            done
            wait
            sleep 1
          done

---
# Multiple consumer groups
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-consumer-group-1
  namespace: strimzi-kafka
spec:
  replicas: 2
  selector:
    matchLabels:
      app: kafka-consumer-group-1
  template:
    metadata:
      labels:
        app: kafka-consumer-group-1
    spec:
      containers:
      - name: consumer
        image: strimzi/kafka:latest-kafka-3.3.1
        resources:
          requests:
            memory: "128Mi"
            cpu: "50m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        command:
        - /bin/bash
        - -c
        - |
          /opt/kafka/bin/kafka-console-consumer.sh \
            --bootstrap-server production-kafka-kafka-bootstrap:9092 \
            --topic test-topic \
            --group consumer-group-1 \
            --consumer-property enable.auto.commit=true \
            --consumer-property auto.commit.interval.ms=1000

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-consumer-group-2
  namespace: strimzi-kafka
spec:
  replicas: 2
  selector:
    matchLabels:
      app: kafka-consumer-group-2
  template:
    metadata:
      labels:
        app: kafka-consumer-group-2
    spec:
      containers:
      - name: consumer
        image: strimzi/kafka:latest-kafka-3.3.1
        resources:
          requests:
            memory: "128Mi"
            cpu: "50m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        command:
        - /bin/bash
        - -c
        - |
          /opt/kafka/bin/kafka-console-consumer.sh \
            --bootstrap-server production-kafka-kafka-bootstrap:9092 \
            --topic metrics-topic \
            --group consumer-group-2 \
            --consumer-property enable.auto.commit=true \
            --consumer-property auto.commit.interval.ms=500

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-consumer-lag-simulator
  namespace: strimzi-kafka
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-consumer-lag-simulator
  template:
    metadata:
      labels:
        app: kafka-consumer-lag-simulator
    spec:
      containers:
      - name: consumer
        image: strimzi/kafka:latest-kafka-3.3.1
        resources:
          requests:
            memory: "128Mi"
            cpu: "50m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        command:
        - /bin/bash
        - -c
        - |
          # Slow consumer to create lag
          /opt/kafka/bin/kafka-console-consumer.sh \
            --bootstrap-server production-kafka-kafka-bootstrap:9092 \
            --topic events-topic \
            --group lag-test-group \
            --max-messages 1 \
            --consumer-property enable.auto.commit=true \
            --consumer-property auto.commit.interval.ms=5000 | \
          while read line; do
            echo "Processing: $line"
            sleep 2  # Simulate slow processing
          done

---
# Job to create initial data
apiVersion: batch/v1
kind: Job
metadata:
  name: kafka-initial-data-loader
  namespace: strimzi-kafka
spec:
  template:
    spec:
      containers:
      - name: loader
        image: strimzi/kafka:latest-kafka-3.3.1
        command:
        - /bin/bash
        - -c
        - |
          echo "Loading initial data..."
          
          # Create topics if they don't exist
          for topic in test-topic metrics-topic events-topic; do
            /opt/kafka/bin/kafka-topics.sh \
              --bootstrap-server production-kafka-kafka-bootstrap:9092 \
              --create --if-not-exists \
              --topic $topic \
              --partitions 3 \
              --replication-factor 3 || true
          done
          
          # Load 1000 messages into each topic
          for topic in test-topic metrics-topic events-topic; do
            echo "Loading data into $topic..."
            for i in {1..1000}; do
              echo "{\"id\":$i,\"timestamp\":$(date +%s),\"data\":\"Initial load message $i\"}"
            done | /opt/kafka/bin/kafka-console-producer.sh \
              --bootstrap-server production-kafka-kafka-bootstrap:9092 \
              --topic $topic
          done
          
          echo "Initial data load complete"
      restartPolicy: OnFailure
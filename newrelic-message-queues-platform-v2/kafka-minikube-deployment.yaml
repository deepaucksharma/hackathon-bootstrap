# Kafka Deployment for Minikube
# This creates a 3-node Kafka cluster with Zookeeper
---
apiVersion: v1
kind: Namespace
metadata:
  name: kafka
---
# Zookeeper Service
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
  namespace: kafka
spec:
  ports:
  - port: 2181
    name: client
  selector:
    app: zookeeper
---
# Zookeeper Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zookeeper
  namespace: kafka
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
    spec:
      containers:
      - name: zookeeper
        image: confluentinc/cp-zookeeper:7.3.0
        ports:
        - containerPort: 2181
        env:
        - name: ZOOKEEPER_CLIENT_PORT
          value: "2181"
        - name: ZOOKEEPER_TICK_TIME
          value: "2000"
---
# Kafka Service (Headless for StatefulSet)
apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  namespace: kafka
spec:
  clusterIP: None
  ports:
  - port: 9092
    name: broker
  - port: 9093
    name: controller
  selector:
    app: kafka
---
# Kafka External Service (NodePort for external access)
apiVersion: v1
kind: Service
metadata:
  name: kafka-external
  namespace: kafka
spec:
  type: NodePort
  ports:
  - port: 9092
    targetPort: 9092
    nodePort: 30092
    name: broker
  selector:
    app: kafka
---
# Kafka StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: kafka
spec:
  serviceName: kafka-headless
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.3.0
        ports:
        - containerPort: 9092
          name: broker
        - containerPort: 9093
          name: controller
        - containerPort: 9999
          name: jmx
        env:
        - name: KAFKA_BROKER_ID_GENERATION_ENABLE
          value: "true"
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper:2181"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: "INTERNAL"
        - name: KAFKA_LISTENERS
          value: "INTERNAL://0.0.0.0:9093,EXTERNAL://0.0.0.0:9092"
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "INTERNAL://$(hostname -f):9093,EXTERNAL://$(minikube ip):30092"
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "true"
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_MIN_INSYNC_REPLICAS
          value: "2"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_JMX_PORT
          value: "9999"
        - name: KAFKA_JMX_HOSTNAME
          value: "localhost"
        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka/data
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 10Gi
---
# Test Producer Job (Optional - generates sample data)
apiVersion: batch/v1
kind: Job
metadata:
  name: kafka-test-producer
  namespace: kafka
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: producer
        image: confluentinc/cp-kafka:7.3.0
        command:
        - /bin/bash
        - -c
        - |
          # Wait for Kafka to be ready
          sleep 30
          
          # Create test topics
          kafka-topics --bootstrap-server kafka-headless:9092 --create --topic orders --partitions 12 --replication-factor 3 --if-not-exists
          kafka-topics --bootstrap-server kafka-headless:9092 --create --topic payments --partitions 12 --replication-factor 3 --if-not-exists
          kafka-topics --bootstrap-server kafka-headless:9092 --create --topic inventory --partitions 6 --replication-factor 3 --if-not-exists
          
          # Produce test messages
          echo "Producing test messages..."
          for i in {1..100}; do
            echo "order-$i: {\"orderId\": $i, \"amount\": $((RANDOM % 1000)), \"timestamp\": $(date +%s)}" | kafka-console-producer --bootstrap-server kafka-headless:9092 --topic orders
            echo "payment-$i: {\"paymentId\": $i, \"orderId\": $i, \"status\": \"completed\"}" | kafka-console-producer --bootstrap-server kafka-headless:9092 --topic payments
            sleep 0.1
          done
          echo "Test data generation complete"
---
# New Relic Infrastructure Agent DaemonSet (with nri-kafka)
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: newrelic-infrastructure
  namespace: kafka
spec:
  selector:
    matchLabels:
      app: newrelic-infrastructure
  template:
    metadata:
      labels:
        app: newrelic-infrastructure
    spec:
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: newrelic-infrastructure
        image: newrelic/infrastructure:latest
        env:
        - name: NRIA_LICENSE_KEY
          valueFrom:
            secretKeyRef:
              name: newrelic-license
              key: license-key
        - name: CLUSTER_NAME
          value: "minikube-kafka-cluster"
        - name: NRIA_VERBOSE
          value: "1"
        - name: NRIA_DISPLAY_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: NRK8S_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        volumeMounts:
        - name: config
          mountPath: /etc/newrelic-infra/integrations.d/
        - name: host-root
          mountPath: /host
          readOnly: true
        securityContext:
          privileged: true
      volumes:
      - name: config
        configMap:
          name: nri-kafka-config
      - name: host-root
        hostPath:
          path: /
---
# ConfigMap for nri-kafka integration
apiVersion: v1
kind: ConfigMap
metadata:
  name: nri-kafka-config
  namespace: kafka
data:
  kafka-config.yml: |
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: minikube-kafka-cluster
          KAFKA_VERSION: "3.3.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "zookeeper.kafka.svc.cluster.local", "port": 2181}]'
          COLLECT_BROKER_TOPIC_DATA: true
          TOPIC_MODE: all
          COLLECT_TOPIC_SIZE: false
        interval: 30s
        labels:
          env: minikube
          role: kafka
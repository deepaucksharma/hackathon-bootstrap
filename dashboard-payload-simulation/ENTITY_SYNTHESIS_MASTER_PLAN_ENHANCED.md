# Entity Synthesis Master Plan - Enhanced Edition

## Part 1: The "Why" - The Theoretical Foundation (The Learnings)

### 1.1 The New Relic Entity Model & entity-definitions

**The Truth**: The `newrelic/entity-definitions` repository provides the synthesis rules, not a simple field map. It tells us how entities are linked and what attributes define their identity (e.g., `aws.accountId + aws.region + aws.kafka.ClusterName` uniquely identifies an MSK cluster).

**Key Insight**: Entity synthesis is a backend process triggered by specific data patterns. Our goal is not just to send data, but to send it in a pattern that activates the correct synthesis rule.

**Deep Technical Details**:
- **Domain**: Must be `INFRA` for all infrastructure entities
- **Type**: Must match exactly: `AWS_KAFKA_CLUSTER`, `AWS_KAFKA_BROKER`, or `AWS_KAFKA_TOPIC`
- **Identifier Components**:
  - Cluster: `{awsAccountId}:{awsRegion}:{clusterName}`
  - Broker: `{awsAccountId}:{awsRegion}:{clusterName}:{brokerId}`
  - Topic: `{awsAccountId}:{awsRegion}:{clusterName}:{topicName}`
- **GUID Construction**: `base64(accountId|domain|type|hash(identifier))`
- **Hash Algorithm**: Uses MurmurHash3 for consistent entity ID generation

**Actionable Consequence**: We must construct our payloads to satisfy these identity-defining attributes precisely. The entity's GUID itself is a base64 encoding of these identity parts.

### 1.2 The Queues & Streams UI Requirements

**The Truth**: The New Relic Q&S UI is not just a generic data visualizer. It is a curated application experience that expects entities to have a specific provider tag and be generated by a trusted source.

**Key Insight**: Analysis of working accounts and our own experiments proved the UI filters for data coming from the `cloud-integrations` collector pipeline, which is used by New Relic's native AWS polling integrations.

**UI Integration Requirements**:
- **Collector Pipeline**: MUST be `cloud-integrations` (case-sensitive)
- **Provider Tag**: MUST match entity type: `AwsMskCluster`, `AwsMskBroker`, or `AwsMskTopic`
- **Instrumentation Provider**: MUST be `aws` (lowercase)
- **Account Linking**: `providerExternalId` MUST match a linked AWS account in New Relic
- **Health Status Calculation**: Based on specific metric thresholds:
  - `UNHEALTHY`: When `offlinePartitionsCount > 0` or `underReplicatedPartitions > 0`
  - `HEALTHY`: All critical metrics within normal ranges
  - `UNKNOWN`: Insufficient data or stale metrics (>5 minutes)

**Actionable Consequence**: All other approaches (mimicking CloudWatch Metric Streams, sending generic Metric events) are incorrect. We must perfectly emulate the `AwsMsk*Sample` event format sent by the polling integrations.

### 1.3 The Data Format: Aggregated Events

**The Truth**: The `cloud-integrations` pipeline sends pre-aggregated data. It doesn't send raw, high-frequency metrics.

**Key Insight**: Every single metric must be accompanied by a full set of five aggregation types: `.Sum`, `.Average`, `.Maximum`, `.Minimum`, and `.SampleCount`. A metric like `provider.bytesInPerSec.Average` without the other four will likely be ignored by UI components.

**Aggregation Requirements**:
- **Time Window**: 60-second aggregation periods
- **Required Aggregations**: ALL five must be present for each metric
  - `.Sum`: Total value over the period
  - `.Average`: Mean value
  - `.Maximum`: Peak value
  - `.Minimum`: Lowest value
  - `.SampleCount`: Number of data points (typically 60 for 1-second samples)
- **Metric Naming**: Must use `provider.` prefix for all custom metrics
- **Data Types**: All metric values MUST be float64, even for counts

**Actionable Consequence**: Our payload generation must perform these aggregations over a simulated time window before sending the data.

## Part 2: The "What" - The Golden Payload Schema

This is the definitive, annotated structure that our platform must produce. It is the blueprint for success.

### 2.1 AwsMskClusterSample - Complete Schema

```jsonc
{
  // --- A. Event & Timestamp ---
  "eventType": "AwsMskClusterSample",     // REQUIRED: Exact string match
  "timestamp": 1672531200000,             // REQUIRED: Unix timestamp in milliseconds

  // --- B. Entity Identity (CRITICAL) ---
  "entityName": "my-local-kafka",         // REQUIRED: The cluster name only
  "entityGuid": "MTIzNDU2Nzg5fElORlJBfEFXU19LQUZLQV9DTFVTVEVSfDEyMzQ1Njc4OQ", // REQUIRED: base64 encoded
  "entityId": 123456789,                  // REQUIRED: Numeric hash of identifier

  // --- C. Collector & Provider Identity (CRITICAL FOR UI VISIBILITY) ---
  "collector.name": "cloud-integrations", // NON-NEGOTIABLE: Magic key for UI
  "instrumentation.provider": "aws",      // REQUIRED: Must be lowercase "aws"
  "provider": "AwsMskCluster",           // REQUIRED: Exact string match

  // --- D. Account Mapping (CRITICAL FOR UI VISIBILITY) ---
  "providerAccountId": "1234567",         // Your New Relic Account ID
  "providerAccountName": "Production",    // Display name in UI
  "providerExternalId": "123456789012",   // Your 12-digit AWS Account ID

  // --- E. AWS Contextual Attributes ---
  "awsAccountId": "123456789012",         // Your 12-digit AWS Account ID
  "awsRegion": "us-east-1",               // The AWS region
  "dataSourceName": "Managed Kafka",      // Static value (legacy field)

  // --- F. Cluster-Specific Identifiers ---
  "provider.clusterName": "my-local-kafka",
  "provider.clusterArn": "arn:aws:kafka:us-east-1:123456789012:cluster/my-local-kafka/uuid",
  "provider.state": "ACTIVE",             // Cluster state
  "provider.kafkaVersion": "2.8.0",       // Kafka version
  "provider.enhancedMonitoring": "PER_BROKER", // Monitoring level

  // --- G. Critical Cluster Metrics (MUST include all 5 aggregations) ---
  "provider.globalPartitionCount.Sum": 150.0,
  "provider.globalPartitionCount.Average": 150.0,
  "provider.globalPartitionCount.Maximum": 150.0,
  "provider.globalPartitionCount.Minimum": 150.0,
  "provider.globalPartitionCount.SampleCount": 60,

  "provider.globalTopicCount.Sum": 25.0,
  "provider.globalTopicCount.Average": 25.0,
  "provider.globalTopicCount.Maximum": 25.0,
  "provider.globalTopicCount.Minimum": 25.0,
  "provider.globalTopicCount.SampleCount": 60,

  "provider.offlinePartitionsCount.Sum": 0.0,
  "provider.offlinePartitionsCount.Average": 0.0,
  "provider.offlinePartitionsCount.Maximum": 0.0,
  "provider.offlinePartitionsCount.Minimum": 0.0,
  "provider.offlinePartitionsCount.SampleCount": 60,

  // Additional metrics following same pattern...
}
```

### 2.2 AwsMskBrokerSample - Complete Schema

```jsonc
{
  // --- A. Event & Timestamp ---
  "eventType": "AwsMskBrokerSample",      // REQUIRED: Exact string match
  "timestamp": 1672531200000,             // REQUIRED: Unix timestamp in milliseconds

  // --- B. Entity Identity (CRITICAL) ---
  "entityName": "1:my-local-kafka",       // REQUIRED: Format "{brokerId}:{clusterName}"
  "entityGuid": "MTIzNDU2Nzg5fElORlJBfEFXU19LQUZLQV9CUk9LRVJ8OTg3NjU0MzIx", // REQUIRED
  "entityId": 987654321,                  // REQUIRED: Hash of broker identifier

  // --- C. Collector & Provider Identity ---
  "collector.name": "cloud-integrations",
  "instrumentation.provider": "aws",
  "provider": "AwsMskBroker",            // REQUIRED: Exact string match

  // --- D. Account Mapping ---
  "providerAccountId": "1234567",
  "providerAccountName": "Production",
  "providerExternalId": "123456789012",

  // --- E. AWS Contextual Attributes ---
  "awsAccountId": "123456789012",
  "awsRegion": "us-east-1",
  "dataSourceName": "Managed Kafka",

  // --- F. Broker-Specific Identifiers ---
  "provider.brokerId": "1",               // REQUIRED: Numeric broker ID
  "provider.clusterName": "my-local-kafka", // REQUIRED: Must match cluster's name
  "provider.brokerState": "RUNNING",      // Broker state

  // --- G. Critical Broker Metrics ---
  "provider.bytesInPerSec.Sum": 150000.0,
  "provider.bytesInPerSec.Average": 2500.0,
  "provider.bytesInPerSec.Maximum": 5000.0,
  "provider.bytesInPerSec.Minimum": 1000.0,
  "provider.bytesInPerSec.SampleCount": 60,

  "provider.bytesOutPerSec.Sum": 120000.0,
  "provider.bytesOutPerSec.Average": 2000.0,
  "provider.bytesOutPerSec.Maximum": 4000.0,
  "provider.bytesOutPerSec.Minimum": 800.0,
  "provider.bytesOutPerSec.SampleCount": 60,

  "provider.cpuIdle.Sum": 5400.0,
  "provider.cpuIdle.Average": 90.0,
  "provider.cpuIdle.Maximum": 95.0,
  "provider.cpuIdle.Minimum": 85.0,
  "provider.cpuIdle.SampleCount": 60,

  "provider.underReplicatedPartitions.Sum": 0.0,
  "provider.underReplicatedPartitions.Average": 0.0,
  "provider.underReplicatedPartitions.Maximum": 0.0,
  "provider.underReplicatedPartitions.Minimum": 0.0,
  "provider.underReplicatedPartitions.SampleCount": 60,

  // Additional metrics...
}
```

### 2.3 AwsMskTopicSample - Complete Schema

```jsonc
{
  // --- A. Event & Timestamp ---
  "eventType": "AwsMskTopicSample",       // REQUIRED: Exact string match
  "timestamp": 1672531200000,             // REQUIRED: Unix timestamp in milliseconds

  // --- B. Entity Identity (CRITICAL) ---
  "entityName": "my-events:my-local-kafka", // REQUIRED: Format "{topicName}:{clusterName}"
  "entityGuid": "MTIzNDU2Nzg5fElORlJBfEFXU19LQUZLQV9UT1BJ!wMTExMTExMTE", // REQUIRED
  "entityId": 111111111,                  // REQUIRED: Hash of topic identifier

  // --- C. Collector & Provider Identity ---
  "collector.name": "cloud-integrations",
  "instrumentation.provider": "aws",
  "provider": "AwsMskTopic",             // REQUIRED: Exact string match

  // --- D. Account Mapping ---
  "providerAccountId": "1234567",
  "providerAccountName": "Production",
  "providerExternalId": "123456789012",

  // --- E. AWS Contextual Attributes ---
  "awsAccountId": "123456789012",
  "awsRegion": "us-east-1",
  "dataSourceName": "Managed Kafka",

  // --- F. Topic-Specific Identifiers ---
  "provider.topicName": "my-events",      // REQUIRED: Topic name
  "provider.clusterName": "my-local-kafka", // REQUIRED: Must match cluster's name
  "provider.partitionCount": 3,          // Number of partitions
  "provider.replicationFactor": 3,       // Replication factor

  // --- G. Topic Metrics ---
  "provider.sumOffsetLag.Sum": 1000.0,
  "provider.sumOffsetLag.Average": 16.67,
  "provider.sumOffsetLag.Maximum": 50.0,
  "provider.sumOffsetLag.Minimum": 0.0,
  "provider.sumOffsetLag.SampleCount": 60,

  "provider.bytesInPerSec.Sum": 30000.0,
  "provider.bytesInPerSec.Average": 500.0,
  "provider.bytesInPerSec.Maximum": 1000.0,
  "provider.bytesInPerSec.Minimum": 200.0,
  "provider.bytesInPerSec.SampleCount": 60,

  // Additional metrics...
}
```

## Part 3: The "How" - The ESVP (Entity Synthesis & Verification Platform)

### Step 3.1: Platform Architecture & Tooling

**Directory Structure**: The refined structure from our previous discussion is perfect. It separates configuration, executable experiments, source code, and results.

**Master Scripts**:
- `1-run-experiment.js`: Executes a single, atomic YAML test file. Ideal for debugging.
- `2-run-campaign.js`: Executes all YAML files in a phase directory (e.g., `phase-2-deconstruction`). This automates the knowledge-building process.

**Configuration (`config/`)**:
- `platform-config.json`: Centralizes all variables (API keys, account IDs, wait times). This keeps tests clean.
- `entity-schema.json`: This file will be the output of the campaign—the programmatically verified "golden schema."

**Enhanced Verification Methods**:
```javascript
// Core entity checks
entityExists(guid)                    // Verifies entity was synthesized
entityIsVisibleInUi(guid)             // Verifies UI visibility
entityHasType(guid, expectedType)     // Verifies correct entity type
entityHasProvider(guid, provider)     // Verifies provider tag

// Relationship checks
relationshipExists(fromGuid, toGuid, type) // Verifies MANAGES/PRODUCES/CONSUMES
entityHasRelationshipCount(guid, count)    // Verifies relationship count

// Health status checks
healthStatusShouldBe(guid, status)    // Verifies HEALTHY/UNHEALTHY/UNKNOWN
entityHasAlertStatus(guid, status)    // Verifies alert conditions

// Metric validation
metricValueInRange(guid, metric, min, max) // Verifies metric values
metricHasAggregations(guid, metric)       // Verifies all 5 aggregations present
```

### Step 3.2: The Execution Campaign - A Rigorous Path to Mastery

This campaign uses the ESVP to leave no stone unturned.

#### Phase 1: Baseline Validation (Control Experiments)
**Goal**: Prove the platform works and validate our core discovery.

**Action**: Run the `phase-1-baseline-validation` campaign.
- `1.1-positive-control.yaml`: Sends the captured golden-payload. Verification: All checks, including `entityIsVisibleInUi`, must PASS.
- `1.2-negative-control-wrong-collector.yaml`: Sends the golden payload but with `collector.name: "nri-kafka"`. Verification: `entityIsVisibleInUi` MUST FAIL.
- `1.3-negative-control-wrong-provider.yaml`: Tests with incorrect provider tag.
- `1.4-negative-control-missing-external-id.yaml`: Tests without AWS account linking.

**Outcome**: A permanent, data-backed artifact proving that the `cloud-integrations` collector is the key.

#### Phase 2: Minimal Viable Payload Deconstruction
**Goal**: Find the absolute minimum set of fields required for UI visibility.

**Action**: Run the `phase-2-deconstruction-analysis` campaign. This campaign directory contains one YAML file for each attribute in the golden payload. Each experiment removes a single attribute.

**Field Classification Results** (from verified testing):
- **MANDATORY_FOR_ENTITY**: 
  - `eventType`, `timestamp`, `entityName`, `entityGuid`, `entityId`
  - `awsAccountId`, `awsRegion`, `provider.clusterName` (or equivalent)
  
- **MANDATORY_FOR_UI**:
  - `collector.name` (MUST be "cloud-integrations")
  - `instrumentation.provider` (MUST be "aws")
  - `provider` (MUST match entity type)
  - `providerExternalId` (MUST match linked AWS account)
  - At least one metric with all 5 aggregations

- **RECOMMENDED**:
  - `providerAccountId`, `providerAccountName`
  - `dataSourceName` (for consistency)
  - All health-related metrics

- **OPTIONAL**:
  - Additional metadata fields
  - Non-critical metrics

**Outcome**: The `results/campaign-log.md` is automatically updated with a table that classifies each attribute.

#### Phase 3: UI Component & Behavior Verification
**Goal**: Confirm how to control specific UI elements.

**Action**: Run the `phase-3-component-verification` campaign.

**Critical UI Behaviors**:
1. **Health Status Triggers**:
   - `provider.offlinePartitionsCount.Sum > 0` → UNHEALTHY
   - `provider.underReplicatedPartitions.Sum > 0` → UNHEALTHY
   - `provider.activeControllerCount.Sum < 1` → UNHEALTHY
   - No data for >5 minutes → UNKNOWN

2. **Relationship Formation**:
   - Broker → Cluster: `provider.clusterName` must match cluster's `entityName`
   - Topic → Cluster: `provider.clusterName` must match cluster's `entityName`
   - Topic → Broker: Formed via partition leadership metrics

3. **UI Sections**:
   - Summary: Requires cluster-level aggregated metrics
   - Brokers: Requires broker entities with relationships
   - Topics: Requires topic entities with lag metrics
   - Consumer Groups: Requires consumer lag data

**Outcome**: A clear understanding of the data-to-UI mapping, codified in executable tests.

#### Phase 4: Full System Simulation & Relationship Synthesis
**Goal**: Verify complex interactions in a multi-entity environment.

**Action**: Run the `2-run-simulation.js` script with a scenario file.

**Scenario** (`simulations/1-full-cluster-lifecycle.yaml`):
```yaml
name: "Full Cluster Lifecycle Simulation"
steps:
  - action: "send_cluster"
    payload: "templates/cluster-healthy.json"
    wait: 10
    
  - action: "send_brokers"
    payloads: 
      - "templates/broker-1.json"
      - "templates/broker-2.json"
      - "templates/broker-3.json"
    wait: 10
    
  - action: "send_topics"
    payloads:
      - "templates/topic-events.json"
      - "templates/topic-logs.json"
    wait: 30
    
  - action: "verify_relationships"
    checks:
      - relationshipExists(cluster.guid, broker1.guid, "MANAGES")
      - relationshipExists(cluster.guid, broker2.guid, "MANAGES")
      - relationshipExists(cluster.guid, broker3.guid, "MANAGES")
      - relationshipExists(topic1.guid, cluster.guid, "PRODUCES")
      - entityHasRelationshipCount(cluster.guid, 5)
```

**Outcome**: Proof that our understanding of entity hierarchy and relationships is correct.

## Part 4: The Final Deliverable - From Platform to Production

### 4.1 Implementation Checklist

The ESVP is not the final product; it is the factory that produces the final specification.

1. **Generate the Golden Schema**: 
   ```bash
   node scripts/generate-schema.js --from-campaign results/phase-2-campaign.json
   ```
   Output: `config/entity-schema.json` with validated field requirements

2. **Implement in nri-kafka**: 
   - Modify `src/msk/shim.go` to implement the aggregation logic
   - Update `src/msk/dimensional_transformer.go` for proper field mapping
   - Ensure `collector.name` is set to "cloud-integrations"
   - Implement proper entity GUID generation using MurmurHash3

3. **CI/CD Integration**: 
   ```yaml
   # .github/workflows/entity-synthesis-validation.yml
   - name: Run Entity Synthesis Validation
     run: |
       npm install
       node 2-run-campaign.js --phase validation
       node scripts/verify-results.js
   ```

4. **Production Monitoring**:
   - Set up alerts for entity synthesis failures
   - Monitor UI visibility metrics
   - Track relationship formation success rates

### 4.2 Verification Checklist

Before considering the implementation complete, verify:

- [ ] **Entity Creation**: All three entity types are created with correct GUIDs
- [ ] **UI Visibility**: Entities appear in Queues & Streams UI
- [ ] **Health Status**: Status reflects actual cluster health
- [ ] **Relationships**: Proper hierarchy (Cluster → Brokers → Topics)
- [ ] **Metrics**: All critical metrics with 5 aggregations
- [ ] **Account Linking**: AWS account properly linked via providerExternalId
- [ ] **Real-time Updates**: Metrics update within 60 seconds
- [ ] **Historical Data**: 8-day retention verified
- [ ] **Alert Conditions**: Health-based alerts trigger correctly
- [ ] **Performance**: <100ms processing time per payload

This ultra-detailed, ground-up solution provides a complete, closed-loop system. It begins with observation, moves to rigorous experimentation, produces a verifiable specification, and provides a mechanism for ongoing automated regression testing. It is the most effective path to a successful and maintainable integration.